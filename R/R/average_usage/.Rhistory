}
# normlise data in percentage format
norm <- function(col_val){
db_sum = sum(col_val)
val = col_val / db_sum * 100
#format(round(val, 2))
}
# Plot graph
draw_graph <- function(){
db_tran <- melt(db_all, id.vars=index_col)
ggplot(db_tran, aes(db_tran[,index_col],value, col=variable, group = variable)) +
geom_line(colour=chart_color) +
geom_point(colour=chart_color) +
labs(list(title = "Average Daily Usage", x = "Time", y = "usage %"))+
theme(axis.text.x = element_text(angle=90, vjust=0.5))
}
#extract file name and rename it
rename_file <- function(f_name){
preName = "nmi"
joinPart = "_"
nmi = substr(f_name, 1, 10)
new_name = paste(preName, nmi, sep = joinPart)
return(new_name)
}
main()
draw_graph()
library(ggplot2)
library(reshape2)
library(scales)
#path = "C:/Users/rfzheng/Desktop/Udacity/R/average_usage"
path = "C:/Users/Ricky/Desktop/Eutility_Dev/R/R/average_usage"
target_col = "kWh"
index_col = "Time"
chart_color = "#000000"
setwd(path)
#loop through all csv files in the given path
csv_files = list.files(pattern="*.csv")
size_temp = length(csv_files)
main <- function(){
if (size_temp >0){
# loop throught all csv files
for(i in 1:size_temp){
# main
result <- parse_file(i, csv_files[i])
next
}
return(result)
}
}
# parse data
parse_file <- function(index, f_name){
db <- fetch_data(f_name)
if(index == 1){
# set up for first time
db_all <<- db
}
#normalise dataset
db_all[[rename_file(f_name)]] <<- norm(db[,rename_file(f_name)])
return(db_all)
}
fetch_data <-function(f_name){
db_raw = read.csv(f_name)
dic_db = list(db_raw$Time)
index_Time <- grep(target_col, colnames(db_raw))
#fetch target column
db <- aggregate(db_raw[, index_Time], dic_db, mean)
#rename fetched database
colnames(db)[1] <- index_col
colnames(db)[2] <- rename_file(f_name)
#sort data by on index
db <- db[order(db$Time),]
return(db)
}
# normlise data in percentage format
norm <- function(col_val){
db_sum = sum(col_val)
val = col_val / db_sum * 100
#format(round(val, 2))
}
# Plot graph
draw_graph <- function(){
db_tran <- melt(db_all, id.vars=index_col)
ggplot(db_tran, aes(db_tran[,index_col],value, col=variable, group = variable)) +
geom_line(colour=chart_color) +
geom_point(colour=chart_color) +
labs(list(title = "Average Daily Usage", x = "Time", y = "usage %"))+
theme(axis.text.x = element_text(angle=90, vjust=0.5))
}
#extract file name and rename it
rename_file <- function(f_name){
preName = "nmi"
joinPart = "_"
nmi = substr(f_name, 1, 10)
new_name = paste(preName, nmi, sep = joinPart)
return(new_name)
}
main()
draw_graph()
library(ggplot2)
library(reshape2)
library(scales)
#path = "C:/Users/rfzheng/Desktop/Udacity/R/average_usage"
path = "C:/Users/Ricky/Desktop/Eutility_Dev/R/R/average_usage"
target_col = "kWh"
index_col = "Time"
chart_color = "#000000"
setwd(path)
#loop through all csv files in the given path
csv_files = list.files(pattern="*.csv")
size_temp = length(csv_files)
main <- function(){
if (size_temp >0){
# loop throught all csv files
for(i in 1:size_temp){
# main
result <- parse_file(i, csv_files[i])
next
}
return(result)
}
}
# parse data
parse_file <- function(index, f_name){
db <- fetch_data(f_name)
if(index == 1){
# set up for first time
db_all <<- db
}
#normalise dataset
db_all[[rename_file(f_name)]] <<- norm(db[,rename_file(f_name)])
return(db_all)
}
fetch_data <-function(f_name){
db_raw = read.csv(f_name)
dic_db = list(db_raw$Time)
index_Time <- grep(target_col, colnames(db_raw))
#fetch target column
db <- aggregate(db_raw[, index_Time], dic_db, mean)
#rename fetched database
colnames(db)[1] <- index_col
colnames(db)[2] <- rename_file(f_name)
#sort data by on index
db <- db[order(db$Time),]
return(db)
}
# normlise data in percentage format
norm <- function(col_val){
db_sum = sum(col_val)
val = col_val / db_sum * 100
#format(round(val, 2))
}
# Plot graph
draw_graph <- function(){
db_tran <- melt(db_all, id.vars=index_col)
ggplot(db_tran, aes(db_tran[,index_col],value, col=variable, group = variable)) +
geom_line(colour=chart_color) +
geom_point(colour=chart_color) +
labs(list(title = "Average Daily Usage", x = "Time", y = "usage %"))+
theme(axis.text.x = element_text(angle=90, vjust=0.5))
}
#extract file name and rename it
rename_file <- function(f_name){
preName = "nmi"
joinPart = "_"
nmi = substr(f_name, 1, 10)
new_name = paste(preName, nmi, sep = joinPart)
return(new_name)
}
main()
draw_graph()
library(ggplot2)
library(reshape2)
library(scales)
#path = "C:/Users/rfzheng/Desktop/Udacity/R/average_usage"
path = "C:/Users/Ricky/Desktop/Eutility_Dev/R/R/average_usage"
target_col = "kWh"
index_col = "Time"
chart_color = "#000000"
setwd(path)
#loop through all csv files in the given path
csv_files = list.files(pattern="*.csv")
size_temp = length(csv_files)
main <- function(){
if (size_temp >0){
# loop throught all csv files
for(i in 1:size_temp){
# main
result <- parse_file(i, csv_files[i])
next
}
return(result)
}
}
# parse data
parse_file <- function(index, f_name){
db <- fetch_data(f_name)
if(index == 1){
# set up for first time
db_all <<- db
}
#normalise dataset
db_all[[rename_file(f_name)]] <<- norm(db[,rename_file(f_name)])
return(db_all)
}
fetch_data <-function(f_name){
db_raw = read.csv(f_name)
dic_db = list(db_raw$Time)
index_Time <- grep(target_col, colnames(db_raw))
#fetch target column
db <- aggregate(db_raw[, index_Time], dic_db, mean)
#rename fetched database
colnames(db)[1] <- index_col
colnames(db)[2] <- rename_file(f_name)
#sort data by on index
db <- db[order(db$Time),]
return(db)
}
# normlise data in percentage format
norm <- function(col_val){
db_sum = sum(col_val)
val = col_val / db_sum * 100
#format(round(val, 2))
}
# Plot graph
draw_graph <- function(){
db_tran <- melt(db_all, id.vars=index_col)
ggplot(db_tran, aes(db_tran[,index_col],value, col=variable, group = variable)) +
#geom_line(colour=chart_color) +
geom_point(colour=chart_color) +
labs(list(title = "Average Daily Usage", x = "Time", y = "Proportion of Usage in Each Hour (%)"))+
theme(axis.text.x = element_text(angle=90, vjust=0.5))
}
#extract file name and rename it
rename_file <- function(f_name){
preName = "nmi"
joinPart = "_"
nmi = substr(f_name, 1, 10)
new_name = paste(preName, nmi, sep = joinPart)
return(new_name)
}
main()
draw_graph()
library(ggplot2)
library(reshape2)
library(scales)
#path = "C:/Users/rfzheng/Desktop/Udacity/R/average_usage"
path = "C:/Users/Ricky/Desktop/Eutility_Dev/R/R/average_usage"
target_col = "kWh"
index_col = "Time"
chart_color = "#000000"
setwd(path)
#loop through all csv files in the given path
csv_files = list.files(pattern="*.csv")
size_temp = length(csv_files)
main <- function(){
if (size_temp >0){
# loop throught all csv files
for(i in 1:size_temp){
# main
result <- parse_file(i, csv_files[i])
next
}
return(result)
}
}
# parse data
parse_file <- function(index, f_name){
db <- fetch_data(f_name)
if(index == 1){
# set up for first time
db_all <<- db
}
#normalise dataset
db_all[[rename_file(f_name)]] <<- norm(db[,rename_file(f_name)])
return(db_all)
}
fetch_data <-function(f_name){
db_raw = read.csv(f_name)
dic_db = list(db_raw$Time)
index_Time <- grep(target_col, colnames(db_raw))
#fetch target column
db <- aggregate(db_raw[, index_Time], dic_db, mean)
#rename fetched database
colnames(db)[1] <- index_col
colnames(db)[2] <- rename_file(f_name)
#sort data by on index
db <- db[order(db$Time),]
return(db)
}
# normlise data in percentage format
norm <- function(col_val){
db_sum = sum(col_val)
val = col_val / db_sum * 100
#format(round(val, 2))
}
# Plot graph
draw_graph <- function(){
db_tran <- melt(db_all, id.vars=index_col)
ggplot(db_tran, aes(db_tran[,index_col],value, col=variable, group = variable)) +
geom_line(colour=chart_color) +
#geom_point(colour=chart_color) +
labs(list(title = "Average Daily Usage", x = "Time", y = "Proportion of Usage in Each Hour (%)"))+
theme(axis.text.x = element_text(angle=90, vjust=0.5))
}
#extract file name and rename it
rename_file <- function(f_name){
preName = "nmi"
joinPart = "_"
nmi = substr(f_name, 1, 10)
new_name = paste(preName, nmi, sep = joinPart)
return(new_name)
}
main()
draw_graph()
library(ggplot2)
library(reshape2)
library(scales)
#path = "C:/Users/rfzheng/Desktop/Udacity/R/average_usage"
path = "C:/Users/Ricky/Desktop/Eutility_Dev/R/R/average_usage"
target_col = "kWh"
index_col = "Time"
chart_color = "#18334e"
setwd(path)
#loop through all csv files in the given path
csv_files = list.files(pattern="*.csv")
size_temp = length(csv_files)
main <- function(){
if (size_temp >0){
# loop throught all csv files
for(i in 1:size_temp){
# main
result <- parse_file(i, csv_files[i])
next
}
return(result)
}
}
# parse data
parse_file <- function(index, f_name){
db <- fetch_data(f_name)
if(index == 1){
# set up for first time
db_all <<- db
}
#normalise dataset
db_all[[rename_file(f_name)]] <<- norm(db[,rename_file(f_name)])
return(db_all)
}
fetch_data <-function(f_name){
db_raw = read.csv(f_name)
dic_db = list(db_raw$Time)
index_Time <- grep(target_col, colnames(db_raw))
#fetch target column
db <- aggregate(db_raw[, index_Time], dic_db, mean)
#rename fetched database
colnames(db)[1] <- index_col
colnames(db)[2] <- rename_file(f_name)
#sort data by on index
db <- db[order(db$Time),]
return(db)
}
# normlise data in percentage format
norm <- function(col_val){
db_sum = sum(col_val)
val = col_val / db_sum * 100
#format(round(val, 2))
}
# Plot graph
draw_graph <- function(){
db_tran <- melt(db_all, id.vars=index_col)
ggplot(db_tran, aes(db_tran[,index_col],value, col=variable, group = variable)) +
geom_line(colour=chart_color) +
#geom_point(colour=chart_color) +
labs(list(title = "Average Daily Usage", x = "Time", y = "Proportion of Usage in Each Hour (%)"))+
theme(axis.text.x = element_text(angle=90, vjust=0.5))
}
#extract file name and rename it
rename_file <- function(f_name){
preName = "nmi"
joinPart = "_"
nmi = substr(f_name, 1, 10)
new_name = paste(preName, nmi, sep = joinPart)
return(new_name)
}
main()
draw_graph()
db_all[1,]
db_all[1,2:-1]
db_all[1,2]
db_all[1,(2,-1)]
db_all[1,2~]
db_all[1,names(db_all)!=Time]
db_all[1,names(db_all)!="Time"]
a = db_all[1,names(db_all)!="Time"]
a
mean(a)
mean(a[1])
a[1]
fit <- kmeans(a, 1)
fit
mydata = c(1,2,3)
fit <- kmeans(mydata, 1)
fit
print(f)
print(fit)
library(cluster)
clusplot(mydata, fit$cluster, color=TRUE, shade=TRUE,
labels=2, lines=0)
fit <- kmeans(mydata, 5)
newiris <- iris
newiris
View(newiris)
View(newiris)
View(db_all)
View(db_all)
set.seed(500)
Data <- scale(iris[,-5]) # notice I am scaling the vectors)
par(cex.lab = 1.2, cex.main = .7)
par(mfrow = c(3,2))
for(i in 1:6) clustergram(Data, k.range = 2:8 , line.width = .004, add.center.points = T)
?clustergram
mydata <- na.omit(mydata) # listwise deletion of missing
mydata <- scale(mydata) # standardize variables
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(mydata,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
wss <- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(mydata,
centers=i)$withinss)
x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2))
colnames(x) <- c("x", "y")
(cl <- kmeans(x, 2))
plot(x, col = cl$cluster)
points(cl$centers, col = 1:2, pch = 8, cex = 2)
x
db_all
library(ggplot2)
library(reshape2)
library(scales)
library(cluster)
#path = "C:/Users/rfzheng/Desktop/Udacity/R/average_usage"
path = "C:/Users/Ricky/Desktop/Eutility_Dev/R/R/average_usage"
target_col = "kWh"
index_col = "Time"
chart_color = "#18334e"
setwd(path)
#loop through all csv files in the given path
csv_files = list.files(pattern="*.csv")
size_temp = length(csv_files)
main <- function(){
if (size_temp >0){
# loop throught all csv files
for(i in 1:size_temp){
# main
result <- parse_file(i, csv_files[i])
next
}
return(result)
}
}
# parse data
parse_file <- function(index, f_name){
db <- fetch_data(f_name)
if(index == 1){
# set up for first time
db_all <<- db
}
#normalise dataset
db_all[[rename_file(f_name)]] <<- norm(db[,rename_file(f_name)])
return(db_all)
}
fetch_data <-function(f_name){
db_raw = read.csv(f_name)
dic_db = list(db_raw$Time)
index_Time <- grep(target_col, colnames(db_raw))
#fetch target column
db <- aggregate(db_raw[, index_Time], dic_db, mean)
#rename fetched database
colnames(db)[1] <- index_col
colnames(db)[2] <- rename_file(f_name)
#sort data by on index
db <- db[order(db$Time),]
return(db)
}
# normlise data in percentage format
norm <- function(col_val){
db_sum = sum(col_val)
val = col_val / db_sum * 100
#format(round(val, 2))
}
# Plot graph
draw_graph <- function(){
db_tran <- melt(db_all, id.vars=index_col)
ggplot(db_tran, aes(db_tran[,index_col],value, col=variable, group = variable)) +
geom_line(colour=chart_color) +
#geom_point(colour=chart_color) +
labs(list(title = "Average Daily Usage", x = "Time", y = "Proportion of Usage in Each Hour (%)"))+
theme(axis.text.x = element_text(angle=90, vjust=0.5))
}
#extract file name and rename it
rename_file <- function(f_name){
preName = "nmi"
joinPart = "_"
nmi = substr(f_name, 1, 10)
new_name = paste(preName, nmi, sep = joinPart)
return(new_name)
}
main()
draw_graph()
